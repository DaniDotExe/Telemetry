from operator import index
import sys
import cv2
import time
import os
import threading
import argparse
import torch
import torch.backends.cudnn as cudnn
import pyrealsense2 as rs2
import numpy as np
import queue
#import matplotlib
#matplotlib.use('Agg')
from matplotlib import pyplot as plt
plt.switch_backend('agg')
import matplotlib.pyplot as plt 
import pandas as pd
from matplotlib.ticker import MaxNLocator

from numpy import random
from pathlib import Path
from PyQt5.QtGui import QImage, QPixmap, QIcon
from PyQt5 import QtWidgets, QtCore

from models.experimental import attempt_load
from utils.datasets import LoadImages, LoadRealSense2
from utils.general import check_img_size, non_max_suppression, apply_classifier, scale_coords, xyxy2xywh, \
    strip_optimizer, set_logging, increment_path
from utils.plots import plot_one_box
from utils.torch_utils import select_device, load_classifier, time_synchronized

from final_gui import Ui_Form
import source

#Variable gobla del stream.
#Variable donde se va a transportar la imagen del stream RGB
#Variables donde se va a almacenar el valor de cada clase de caving para posteriormente graficar 
Angular_detected, Tabular_detected,Retrabajados_detected, Blocoso_detected, Splintered_detected, SlickenSides_detected  = 0,0,0,0,0,0
clases_finales = ([0,0,0,0,0,0])
conteo_dinamico = ([0,0,0,0,0,0])
#q = queue.Queue()
#q2 = queue.Queue()
doble_frame=[]
finalizador=False
finalizador2=False
altura_min = 2
manual_conf=False
manual_conf1=False
decision_dinamicos=True
sensor_velocidad = 330
mode_clasificacion = True
activador_dinamico = False
model_6 = True

class Worker(QtCore.QObject):
    finished = QtCore.pyqtSignal()
    live_stream = QtCore.pyqtSignal(np.ndarray)
    live_depth = QtCore.pyqtSignal(np.ndarray)
    detectado = []
    cuenta = 0
    
    def detect(self,save_img=False):
        if model_6 == True:
            modelo_usado = 'estatico'
        else:
            modelo_usado = 'cuatro_clases'
        parser = argparse.ArgumentParser()
        parser.add_argument('--weights', nargs='+', type=str, default=f'./weights/{modelo_usado}.pt', help='model.pt path(s)')
        parser.add_argument('--source', type=str, default='0', help='source')  # file/folder, 0 for webcam
        parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')
        parser.add_argument('--conf-thres', type=float, default=0.6, help='object confidence threshold')
        parser.add_argument('--iou-thres', type=float, default=0.45, help='IOU threshold for NMS')
        parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
        parser.add_argument('--view-img', action='store_true', help='display results')
        parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')
        parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')
        parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 0 2 3')
        parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')
        parser.add_argument('--augment', action='store_true', help='augmented inference')
        parser.add_argument('--update', action='store_true', help='update all models')
        parser.add_argument('--project', default='runs/detect', help='save results to project/name')
        parser.add_argument('--name', default='exp', help='save results to project/name')
        parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
        opt = parser.parse_args()
        print(opt)
        
        global volumen_visor
        global Angular_detected, Tabular_detected, Splintered_detected, SlickenSides_detected, Retrabajados_detected, Blocoso_detected
        global clases_finales, conteo_dinamico
        caving_YOLO =[]
        global altura_min
        source, weights, view_img, save_txt, imgsz = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size
        webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(
            ('rtsp://', 'rtmp://', 'http://'))

        # Directories
        save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run
        (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir

        # Initialize
        set_logging()
        device = select_device(opt.device)
        half = device.type != 'cpu'  # half precision only supported on CUDA

        # Load model
        model = attempt_load(weights, map_location=device)  # load FP32 model
        imgsz = check_img_size(imgsz, s=model.stride.max())  # check img_size
        if half:
            model.half()  # to FP16

        # Second-stage classifier
        classify = False
        if classify:
            modelc = load_classifier(name='resnet101', n=2)  # initialize
            modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()

        # Set Dataloader
        vid_path, vid_writer = None, None
        if webcam:
            view_img = True
            #torch.backends.cudnn.benchmark=True
            cudnn.benchmark = True  # set True to speed up constant image size inference
            dataset = LoadRealSense2(width=640,height=480,fps=30)
        else:
            save_img = True
            dataset = LoadImages(source, img_size=imgsz)

        # Get names and colors
        names = model.module.names if hasattr(model, 'module') else model.names
        colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]

        # Run inference
        t0 = time.time()
        img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img
        _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once
        
        for path, depth, distance, depth_scale, img, im0s, vid_cap in dataset:
            global finalizador
            if finalizador==True:
                break
            img = torch.from_numpy(img).to(device)
            img = img.half() if half else img.float()  # uint8 to fp16/32
            img /= 255.0  # 0 - 255 to 0.0 - 1.0
            if img.ndimension() == 3:
                img = img.unsqueeze(0)

            # Inference
            t1 = time_synchronized()
            pred = model(img, augment=opt.augment)[0]

            # Apply NMS
            pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)
            t2 = time_synchronized()

            # Apply Classifier
            if classify:
                pred = apply_classifier(pred, modelc, img, im0s)

            # Process detections
            
            for i, det in enumerate(pred):  # detections per image
                if webcam:  # batch_size >= 1
                    p, s, im0 = Path(path[i]), '%g: ' % i, im0s[i].copy()
                else:
                    p, s, im0 = Path(path), '', im0s

                save_path = str(save_dir / p.name)
                #txt_path = str(save_dir / 'labels' / p.stem) + ('_%g' % dataset.frame if dataset.mode == 'video' else '')
                s += '%gx%g ' % img.shape[2:]  # print string

                gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh
            
                Angular_detected = 0
                Tabular_detected = 0
                Splintered_detected = 0
                Retrabajados_detected = 0
                SlickenSides_detected = 0
                Blocoso_detected = 0
                volumen_visor = 0
                if len(det):
                    # Rescale boxes from img_size to im0 size
                    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()

                    # Print results
                    for c in det[:, -1].unique():
                        n = (det[:, -1] == c).sum()  # detections per class
                        s += '%g %ss, ' % (n, names[int(c)])  # add to string

                        clase_detectada =  '%s' % names[int(c)]

                        if clase_detectada == 'Angular':
                            Angular_detected = int('%g' % n)
                        
                        if clase_detectada == 'Tabular':
                            Tabular_detected = int('%g' % n)

                        if clase_detectada == 'Splintered':
                            Splintered_detected = int('%g' % n)
                        
                        if clase_detectada == 'Retrabajados':
                            Retrabajados_detected = int('%g' % n)
                        
                        if clase_detectada == 'SlickenSide':
                            SlickenSides_detected = int('%g' % n)

                        if clase_detectada == 'Blocoso':
                            Blocoso_detected = int('%g' % n)

                    # Write results
                    for *xyxy, conf, cls in reversed(det):
                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh
                        line = (cls, *xywh, conf) if opt.save_conf else (cls, *xywh)  # label format
                    
                        yolotxt=('%g ' * len(line) + '\n') % line
                        yololist=list(yolotxt)
                        p1=yololist[0:1]
                        p1=''.join(p1)
                        yololist.pop(0)
                        yololist.pop(0)
                        hp2=yololist.index(' ')
                        p2=yololist[0:hp2] 
                        p2=''.join(p2)
                        for i in range(hp2+1):
                            yololist.pop(0)
                        hp3=yololist.index(' ')
                        p3=yololist[0:hp3] 
                        p3=''.join(p3)
                        for i in range(hp3+1):
                            yololist.pop(0)
                        hp4=yololist.index(' ')
                        p4=yololist[0:hp4] 
                        p4=''.join(p4)
                        for i in range(hp4+1):
                            yololist.pop(0)
                        p5=yololist
                        p5=''.join(p5)
                        
                        
                        caving_YOLO = [int(p1),float(p2),float(p3),float(p4),float(p5)]  

                        altura = self.promedio_altura1(int(float(p2)*640),int(float(p3)*480),int(float(p4)*640),int(float(p5)*480), distance)

                        if manual_conf == True:
                            altura = altura_min
                        
                        #print("holaaaaaaaaaaaaaa",altura)
                        try:
                            volumen_visor1 = altura*(int(float(p4)*320))*(int(float(p5)*240))
                        except:
                            volumen_visor1 = 0    

                        volumen_visor = volumen_visor + volumen_visor1

                        if save_img or view_img:  # Add bbox to image
                            label = '%s %.2f' % (names[int(cls)], conf)
                            plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=3)
                
                #print('--------------one frame----------')
                # Print time (inference + NMS)
                clases_finales = np.array([Angular_detected,Tabular_detected,Splintered_detected,Retrabajados_detected,SlickenSides_detected,Blocoso_detected])
                self.dinamizador(clases_finales,caving_YOLO)
                #print(f'------{Angular_detected}------{Tabular_detected}-----{Splintered_detected}-------{Retrabajados_detected}-------{SlickenSides_detected}-----------{Blocoso_detected}')
                print('%sDone. (%.3fs)' % (s, t2 - t1))
                    


                if view_img:
                    #cv2.imshow(str(p), im0)
                    self.live_stream.emit(im0)
                    self.live_depth.emit(depth)

                    if cv2.waitKey(1) == ord('q'):  # q to quit
                        raise StopIteration          

        print('Done. (%.3fs)' % (time.time() - t0))
        self.finished.emit()

    def detect2(self,save_img=False):
        parser = argparse.ArgumentParser()
        parser.add_argument('--weights', nargs='+', type=str, default='./weights/one.pt', help='model.pt path(s)')
        parser.add_argument('--source', type=str, default='0', help='source')  # file/folder, 0 for webcam
        parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')
        parser.add_argument('--conf-thres', type=float, default=0.6, help='object confidence threshold')
        parser.add_argument('--iou-thres', type=float, default=0.45, help='IOU threshold for NMS')
        parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
        parser.add_argument('--view-img', action='store_true', help='display results')
        parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')
        parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')
        parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 0 2 3')
        parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')
        parser.add_argument('--augment', action='store_true', help='augmented inference')
        parser.add_argument('--update', action='store_true', help='update all models')
        parser.add_argument('--project', default='runs/detect', help='save results to project/name')
        parser.add_argument('--name', default='exp', help='save results to project/name')
        parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
        opt = parser.parse_args()
        print(opt)
        
        global volumen_visor
        global Angular_detected, Tabular_detected, Splintered_detected, SlickenSides_detected, Retrabajados_detected, Blocoso_detected
        global clases_finales, conteo_dinamico
        caving_YOLO =[]
        global altura_min
        source, weights, view_img, save_txt, imgsz = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size
        webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(
            ('rtsp://', 'rtmp://', 'http://'))

        # Directories
        save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run
        (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir

        # Initialize
        set_logging()
        device = select_device(opt.device)
        half = device.type != 'cpu'  # half precision only supported on CUDA

        # Load model
        model = attempt_load(weights, map_location=device)  # load FP32 model
        imgsz = check_img_size(imgsz, s=model.stride.max())  # check img_size
        if half:
            model.half()  # to FP16

        # Second-stage classifier
        classify = False
        if classify:
            modelc = load_classifier(name='resnet101', n=2)  # initialize
            modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()

        # Set Dataloader
        vid_path, vid_writer = None, None
        if webcam:
            view_img = True
            #torch.backends.cudnn.benchmark=True
            cudnn.benchmark = True  # set True to speed up constant image size inference
            dataset = LoadRealSense2(width=640,height=480,fps=30)
        else:
            save_img = True
            dataset = LoadImages(source, img_size=imgsz)

        # Get names and colors
        names = model.module.names if hasattr(model, 'module') else model.names
        colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]

        # Run inference
        t0 = time.time()
        img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img
        _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once
        
        for path, depth, distance, depth_scale, img, im0s, vid_cap in dataset:
            global finalizador2
            if finalizador2==True:
                break
            img = torch.from_numpy(img).to(device)
            img = img.half() if half else img.float()  # uint8 to fp16/32
            img /= 255.0  # 0 - 255 to 0.0 - 1.0
            if img.ndimension() == 3:
                img = img.unsqueeze(0)

            # Inference
            t1 = time_synchronized()
            pred = model(img, augment=opt.augment)[0]

            # Apply NMS
            pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)
            t2 = time_synchronized()

            # Apply Classifier
            if classify:
                pred = apply_classifier(pred, modelc, img, im0s)

            # Process detections
            
            for i, det in enumerate(pred):  # detections per image
                if webcam:  # batch_size >= 1
                    p, s, im0 = Path(path[i]), '%g: ' % i, im0s[i].copy()
                else:
                    p, s, im0 = Path(path), '', im0s

                save_path = str(save_dir / p.name)
                #txt_path = str(save_dir / 'labels' / p.stem) + ('_%g' % dataset.frame if dataset.mode == 'video' else '')
                s += '%gx%g ' % img.shape[2:]  # print string

                gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh
            
                Angular_detected = 0
                Tabular_detected = 0
                Splintered_detected = 0
                Retrabajados_detected = 0
                SlickenSides_detected = 0
                Blocoso_detected = 0
                caving_detected = 0
                volumen_visor = 0

                if len(det):
                    # Rescale boxes from img_size to im0 size
                    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()

                    # Print results
                    for c in det[:, -1].unique():
                        n = (det[:, -1] == c).sum()  # detections per class
                        s += '%g %ss, ' % (n, names[int(c)])  # add to string

                        clase_detectada =  '%s' % names[int(c)]
                       
                        caving_detected = int('%g' % n)

                    # Write results
                    for *xyxy, conf, cls in reversed(det):
                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh
                        line = (cls, *xywh, conf) if opt.save_conf else (cls, *xywh)  # label format
                    
                        yolotxt=('%g ' * len(line) + '\n') % line
                        yololist=list(yolotxt)
                        p1=yololist[0:1]
                        p1=''.join(p1)
                        yololist.pop(0)
                        yololist.pop(0)
                        hp2=yololist.index(' ')
                        p2=yololist[0:hp2] 
                        p2=''.join(p2)
                        for i in range(hp2+1):
                            yololist.pop(0)
                        hp3=yololist.index(' ')
                        p3=yololist[0:hp3] 
                        p3=''.join(p3)
                        for i in range(hp3+1):
                            yololist.pop(0)
                        hp4=yololist.index(' ')
                        p4=yololist[0:hp4] 
                        p4=''.join(p4)
                        for i in range(hp4+1):
                            yololist.pop(0)
                        p5=yololist
                        p5=''.join(p5)
                        
                        
                        caving_YOLO = [int(p1),float(p2),float(p3),float(p4),float(p5)]  

                        altura = self.promedio_altura1(int(float(p2)*640),int(float(p3)*480),int(float(p4)*640),int(float(p5)*480), distance)
    
                        if manual_conf == True:
                            altura = altura_min

                        #print("holaaaaaaaaaaaaaa",altura)
                        try:
                            volumen_visor1 = altura*(int(float(p4)*320))*(int(float(p5)*240))
                        except:
                            volumen_visor1 = 0    

                        volumen_visor = volumen_visor + volumen_visor1

                        if save_img or view_img:  # Add bbox to image
                            label = '%s %.2f' % (names[int(cls)], conf)
                            plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=3)
                
            
                #print('--------------one frame----------')
                # Print time (inference + NMS)

                clases_finales = np.array([0,0,caving_detected,0,0,0])
                self.dinamizador(clases_finales,caving_YOLO)
                #print(f'------{Angular_detected}------{Tabular_detected}-----{Splintered_detected}-------{Retrabajados_detected}-------{SlickenSides_detected}-----------{Blocoso_detected}')
                print('%sDone. (%.3fs)' % (s, t2 - t1))
                    


                if view_img:
                    #cv2.imshow(str(p), im0)
                    self.live_stream.emit(im0)
                    self.live_depth.emit(depth)

                    if cv2.waitKey(1) == ord('q'):  # q to quit
                        raise StopIteration          

        print('Done. (%.3fs)' % (time.time() - t0))
        self.finished.emit()

    def promedio_altura1(self,x,y,w,h,distance):
        global altura
        global manual_conf
        try:
            detectado1 = self.detectado[y-(0.8*h):y+(0.8*h),x-(0.8*w):x+(0.8*w)] #tomamos el arreglo de numpy con los valores de distancia que nos da el sensor y lo acotamos al 80% para que tome mas acertadamente el caving
            promedio_number = np.mean(detectado1[:,:]) #hacemos un promedio al area ya mas acotada para saber la altura aproximada del caving
        except:
            promedio_number = 320 #320 es porque la altura a la que va a estar la maquina es a 320 mm

        if promedio_number >= 315:
            altura = 2
        else:
            detectado2 = self.detectado[y-h:(y-0.8*h), x-w:x-(0.8*w)] #tomamos el arreglo de numpy con los valores de distancia que nos da el sensor y tomamos su parte que quitamos anteriormente, es decir, el fondo
            detectado3 = self.detectado[y+(0.8*h):(y+h), x+(0.8*w):(x+w)] #tomamos el arreglo de numpy con los valores de distancia que nos da el sensor y tomamos su parte que quitamos anteriormente, es decir, el fondo

            promedio_fondo1 = np.mean(detectado2[:,:])  #hacemos un promedio a la altura aproximada del fondo
            promedio_fondo2 = np.mean(detectado3[:,:])   #hacemos un promedio a la altura aproximada del fondo
            fondo = (promedio_fondo1 + promedio_fondo2) / 2   #hacemos un promedio a la altura aproximada del fondo
            try:
                altura = fondo - promedio_number
            except:
                #altura = 320 - promedio_number    
                altura = 0     

        self.detectado = distance
        return altura      

    def dinamizador(self,clases_finales_f,frames):
        conteo_correcto = False
        global sensor_velocidad
        global activador_dinamico
        franja = sensor_velocidad/480

        if manual_conf1 ==True:
            print(f'manual{franja}')
            try:
                if frames[2]<0.5:
                    if frames[2]>franja:
                        self.cuenta = self.cuenta+1
                        conteo_correcto = True
                        activador_dinamico = True
                        print(f'cuenta{self.cuenta}')
            except:
                pass
            
        else:
            try:
                if frames[2]<0.5:
                    if frames[2]>0.49:
                        self.cuenta = self.cuenta+1
                        conteo_correcto = True
                        activador_dinamico = True
                        print(f'cuenta{self.cuenta}')
            except:
                pass


        
        #print(yololist)
        if decision_dinamicos==True:
            if conteo_correcto ==True:
                conteo_dinamico[0] = clases_finales_f[0] + conteo_dinamico[0] 
                conteo_dinamico[1] = clases_finales_f[1] + conteo_dinamico[1]
                conteo_dinamico[2] = clases_finales_f[2] + conteo_dinamico[2]
                conteo_dinamico[3] = clases_finales_f[3] + conteo_dinamico[3]
                conteo_dinamico[4] = clases_finales_f[4] + conteo_dinamico[4]
                conteo_dinamico[5] = clases_finales_f[5] + conteo_dinamico[5]
                conteo_correcto = False
            
        else:
            conteo_dinamico[0] = clases_finales_f[0] 
            conteo_dinamico[1] = clases_finales_f[1]
            conteo_dinamico[2] = clases_finales_f[2]
            conteo_dinamico[3] = clases_finales_f[3]
            conteo_dinamico[4] = clases_finales_f[4]
            conteo_dinamico[5] = clases_finales_f[5]        

class MainWindow(QtWidgets.QWidget):
    
    #Se declaran las variables que se van a usar para comunicar la interfaz con el yolo como goblales para poder realizar esa comunciacion
    global Angular_detected, Tabular_detected,Retrabajados_detected, Blocoso_detected, Splintered_detected, SlickenSides_detected
    global clases_finales
    
   
    plt = plt
    i= -1
    s = []    
    t = []      
    textos,textos1, textos3 = 0,0,1

    #Estructura de la tabla de cavings/min
    #Se inicia el registro del caving en 0 para que al llegar a 29 se guarde media hora de los datos registrados
    registro_cavings_min=0
    registro_cavings_min2=0
    registro_cavings_hour=0
    registro_cavings_hour2=0
    #Son los 3 indices inicializados en '' para poder graficas mas adelante
    index_date = ['','','','','','','','','','','','','','','','','','','','','','','','','','','','','',''] #es la ventana de indices que se van a mostrar 
    #Son las 6 clases inicializados en 0 para poder graficas mas adelante
    data_cavings={ #es la ventana de datos que se van a mostrar 
        "Angular":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
        "Tabular":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
        "Retrabajados":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
        "Blocoso":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
        "Splintered":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
        "SlickenSides":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
        "cavings":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
    }

    data_cavings2={ #es la ventana de datos que se van a mostrar 
        "Angular":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
        "Tabular":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
        "Retrabajados":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
        "Blocoso":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
        "Splintered":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
        "SlickenSides":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
        "cavings":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
    }

    index_date2 = ['','','','','','','','','','','','','','','','','','','','','','','','','','','','','','']
    data_mass = {
        "gr/min":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
    }

    data_mass2 = {
        "gr/hora":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
    }

    #Se define la altura minima por defecto 1.5mm
    #altura = 1.5
    # Valor inciial que va a mostrarse en la pantalla del volumen
    volumen_visor = 0
    density = 2.3
    guardador_masa = 0
    registro_ciclos = 0
    registro_ciclos2 = 0

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        #Se cargan los datos de la interfaz ya creada
        self.ui = Ui_Form()
        self.ui.setupUi(self) 

        #Se le asigna el logo 
        self.setWindowIcon(QIcon("./imagenes/logo.png"))
        #Se inicializan las tablas 2 y 3 para que se pueda ver la tabla sin valores
        self.ViewTable2()
        self.ViewTable3()
        self.ViewTable4()
        self.ViewTable5()


        #Se crean los timers que son lo ciclos que nos dicen cada cuanto se actualiza algo en la interfaz
        
        self.timer3 = QtCore.QTimer() #timer tabla1
        self.timer4 = QtCore.QTimer() #timer min tab2
        self.timer4_2 = QtCore.QTimer() #timer min tab2
        self.timer5 = QtCore.QTimer() #timer hour tab3

        #Cada timer con cual funcion esta conectado
        
        self.timer3.timeout.connect(self.ViewTable)
        self.timer5.timeout.connect(self.ViewTable_1)
        self.timer4.timeout.connect(self.ViewTable2)
        self.timer4.timeout.connect(self.ViewTable3)
        self.ui.START_5.clicked.connect(self.change_class)
        self.ui.START_6.clicked.connect(self.change_class)

        self.ui.density_change.clicked.connect(self.onChangeText)
        self.ui.altura_change.clicked.connect(self.onChangeText2)
        self.ui.velocidad_change.clicked.connect(self.onChangeText3)
        self.ui.altura_change_auto.clicked.connect(self.auto_configuracion)
  
        #Definimos que cuando presionamos el boton start inciia la funcion On
        self.ui.START.clicked.connect(self.On)
        self.ui.START_2.clicked.connect(self.dinamicos_estaticos)
        self.ui.START_3.clicked.connect(self.On2)
        self.ui.START_4.clicked.connect(self.estaticos_dinamicos)

        #self.dinamicos_estaticos()

        #Difinimos que cuando presionamos el boton quit inicia la funcion QuitALL
        self.ui.QUIT.clicked.connect(self.QuitAll)
        #Titulo de la ventana
        self.setWindowTitle("Cava")


    #Funcion que inicia la interfaz
    def On(self):
        global mode_clasificacion
        mode_clasificacion=True
        textos2=self.textos
        textos3=self.textos3
        if textos2==0:
            global finalizador
            self.ui.START_5.setEnabled(False)
            self.ui.START_6.setEnabled(False)
            #La tabla uno se le puso 15ms para que no varie tanto con la grafica debido a que el yolo es muy rapido ( se puede aumentar o quitar dependiendo de como se comporte)
            self.timer3.start(300)
            #Cada cuando tiempo se actualiza la tabla 3 y 4
            self.timer4.start(60000)
            self.yolo_v5()
            finalizador = False
            # boton resets
            self.ui.START.setText("PARAR")
            # Final resets
            self.ui.START_3.hide()
            self.ui.START_3.setEnabled(False)
            if textos3 == 1:
                self.ui.START_4.hide()
                self.ui.START_4.setEnabled(False)
            else:
                self.ui.START_2.hide()
                self.ui.START_2.setEnabled(False)
            self.thread.finished.connect(
                lambda: self.ui.START.setEnabled(True)
            )
            self.ui.START.setStyleSheet("color: white;\n"
            "border-radius: 50px;\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:1, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(214, 36, 37));\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:1, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(214, 36, 37));\n"
            "\n"
            "")
            self.textos=1
            
            self.ui.Titlle_10.setText("S:Splintered")
            self.ui.Titlle_6.setText("S")
            self.ui.a_n.setText("0")
            self.ui.a_n_2.setText("0")
            self.ui.a_n_3.setText("0")
            self.ui.a_n_4.setText("0")
            self.ui.a_n_5.setText("0")
            self.ui.a_n_6.setText("0")

        else:
            self.ui.START_5.setEnabled(True)
            self.ui.START_6.setEnabled(True)
            self.timer3.stop()
            self.timer4.stop()
            finalizador=True
            self.ui.START.setText("CLASIFICAR")
            self.ui.START_2.show()
            self.ui.START_3.show()
            self.ui.START_4.show()

            self.ui.START.setEnabled(True)
            self.ui.START_2.setEnabled(True)
            self.ui.START_3.setEnabled(True)
            self.ui.START_4.setEnabled(True)

            self.ui.START.setStyleSheet("color: white;\n"
            "border-radius: 50px;\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:1, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(112, 225, 204));\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:1, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(31, 119, 180));\n"
            "\n"
            "")
            self.textos=0

    def On2(self):
        global mode_clasificacion
        mode_clasificacion=False
        textos2=self.textos1
        textos3=self.textos3
        if textos2==0:
            global finalizador2
            self.ui.START_5.hide()
            self.ui.START_6.hide()
            #La tabla uno se le puso 15ms para que no varie tanto con la grafica debido a que el yolo es muy rapido ( se puede aumentar o quitar dependiendo de como se comporte)
            self.timer5.start(300)
            #Cada cuando tiempo se actualiza la tabla 3 y 4
            self.timer4.start(60000)
            self.yolo_v5_2()
            finalizador2 = False
            # boton resets
            self.ui.START_3.setText("PARAR")

            # Final resets
            self.ui.START.hide()
            self.ui.START.setEnabled(False)
            if textos3 == 1:
                self.ui.START_4.hide()
                self.ui.START_4.setEnabled(False)
            else:
                self.ui.START_2.hide()
                self.ui.START_2.setEnabled(False)
            self.thread.finished.connect(
                lambda: self.ui.START.setEnabled(True)
            )
            self.ui.START_3.setStyleSheet("color: white;\n"
            "border-radius: 50px;\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:1, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(214, 36, 37));\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:1, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(214, 36, 37));\n"
            "\n"
            "")
            self.textos1=1
            
            self.ui.Titlle_6.setText("C")
            self.ui.Titlle_10.setText("C:Cavings")
            self.ui.a_n.setText("0")
            self.ui.a_n_2.setText("0")
            self.ui.a_n_3.setText("0")
            self.ui.a_n_4.setText("0")
            self.ui.a_n_5.setText("0")
            self.ui.a_n_6.setText("0")
            

        else:
            #self.timer3.stop()
            finalizador2=True
            self.ui.START_5.show()
            self.ui.START_6.show()

            self.timer5.stop()
            self.timer4.stop()

            self.ui.START.show()
            self.ui.START_2.show()
            self.ui.START_4.show()

            self.ui.START.setEnabled(True)
            self.ui.START_2.setEnabled(True)
            self.ui.START_3.setEnabled(True)
            self.ui.START_4.setEnabled(True)

            self.ui.START_3.setText("FLUJO MASICO")
            self.ui.START_3.setStyleSheet("color: white;\n"
            "border-radius: 50px;\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:1, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(112, 225, 204));\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:1, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(31, 119, 180));\n"
            "\n"
            "")
            self.textos1=0

    def change_class(self):
        global model_6

        if model_6 == True:
            model_6 = False
            self.ui.START_5.setStyleSheet("color: white;\n"
            "border-radius: 50px;\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:0.9, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(112, 225, 204));\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:0.9, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(31, 119, 180));\n"
            "background-color: transparent;\n"
            "\n"
            "")
            self.ui.START_6.setStyleSheet("color: white;\n"
            "border-radius: 50px;\n"
            "background-color: rgb(72, 170, 50);\n"
            "\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:0.9, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(72, 170, 50));\n"
            "\n"
            "")
        else:
            model_6 = True
            self.ui.START_5.setStyleSheet("color: white;\n"
            "border-radius: 50px;\n"
            "background-color: rgb(72, 170, 50);\n"
            "\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:0.9, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(72, 170, 50));\n"
            "\n"
            "")
            self.ui.START_6.setStyleSheet("color: white;\n"
            "border-radius: 50px;\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:0.9, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(112, 225, 204));\n"
            "background-color: qlineargradient(spread:pad, x1:0.5, y1:0.9, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(31, 119, 180));\n"
            "background-color: transparent;\n"
            "\n"
            "")
    
    def dinamicos_estaticos(self):
        global decision_dinamicos
        decision_dinamicos = True
        print(f'decision_dinamicos{decision_dinamicos}')
        self.ui.START_4.setStyleSheet("color: white;\n"
        "border-radius: 50px;\n"
        "background-color: qlineargradient(spread:pad, x1:0.5, y1:1, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(112, 225, 204));\n"
        "background-color: qlineargradient(spread:pad, x1:0.5, y1:1, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(31, 119, 180));\n"
        "\n"
        "")
        self.ui.START_2.setStyleSheet("color: white;\n"
        "border-radius: 50px;\n"
        "background-color: rgb(72, 170, 50);\n"
        "\n"
        "background-color: qlineargradient(spread:pad, x1:0.5, y1:0.9, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(72, 170, 50));\n"
        "\n"
        "")
        self.textos3=1
    
    def estaticos_dinamicos(self):
        global decision_dinamicos
        decision_dinamicos = False
        print(f'decision_dinamicos{decision_dinamicos}')
        self.ui.START_2.setStyleSheet("color: white;\n"
        "border-radius: 50px;\n"
        "background-color: qlineargradient(spread:pad, x1:0.5, y1:1, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(112, 225, 204));\n"
        "background-color: qlineargradient(spread:pad, x1:0.5, y1:1, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(31, 119, 180));\n"
        "\n"
        "")
        self.ui.START_4.setStyleSheet("color: white;\n"
        "border-radius: 50px;\n"
        "background-color: rgb(72, 170, 50);\n"
        "\n"
        "background-color: qlineargradient(spread:pad, x1:0.5, y1:0.9, x2:0.5, y2:0, stop:0 rgba(0, 0, 0, 0), stop:1 rgb(72, 170, 50));\n"
        "\n"
        "")
        self.textos3=0

    def yolo_v5(self):
        # Step 2: Create a QThread object
        self.thread = QtCore.QThread()
        # Step 3: Create a worker object
        self.worker = Worker()
        # Step 4: Move worker to the thread
        self.worker.moveToThread(self.thread)
        # Step 5: Connect signals and slots
        self.thread.started.connect(self.worker.detect)
        self.worker.finished.connect(self.thread.quit)
        self.worker.finished.connect(self.worker.deleteLater)
        self.thread.finished.connect(self.thread.deleteLater)
        self.worker.live_stream.connect(self.viewCam)
        self.worker.live_depth.connect(self.ViewDepth)
        # Step 6: Start the thread
        self.thread.start()

    def yolo_v5_2(self):
        # Step 2: Create a QThread object
        self.thread = QtCore.QThread()
        # Step 3: Create a worker object
        self.worker = Worker()
        # Step 4: Move worker to the thread
        self.worker.moveToThread(self.thread)
        # Step 5: Connect signals and slots
        self.thread.started.connect(self.worker.detect2)
        self.worker.finished.connect(self.thread.quit)
        self.worker.finished.connect(self.worker.deleteLater)
        self.thread.finished.connect(self.thread.deleteLater)
        self.worker.live_stream.connect(self.viewCam)
        self.worker.live_depth.connect(self.ViewDepth)
        # Step 6: Start the thread
        self.thread.start()

    def onChangeText(self):
        input_density = self.ui.lineEdit.text()
        try:
            self.density = float(input_density)
        except:
            self.density = 2.3 
            self.ui.lineEdit.setText('2.3')

    def onChangeText2(self):
        global altura_min
        global manual_conf
        manual_conf = True
        input_min_altura = self.ui.lineEdit_2.text()
        try:
            altura_min = float(input_min_altura)
        except:
            altura_min = 2
            self.ui.lineEdit_2.setText('2')

    def auto_configuracion(self):
        global manual_conf
        manual_conf = False
        self.ui.lineEdit_2.setText('2')

    def onChangeText3(self):
        print('---yes---')
        global sensor_velocidad
        global manual_conf1
        manual_conf1 = True
        input_sensor_velocidad = self.ui.lineEdit_5.text()
        try:
            sensor_velocidad = float(input_sensor_velocidad)
        except:
            sensor_velocidad = 230
            self.ui.lineEdit.setText('230')

    #Funciona para visualizar el stream RGB
    def viewCam(self, im0):
        try:
            image_detect = im0
            #conversion a RGB
            image = cv2.cvtColor(image_detect, cv2.COLOR_BGR2RGB)
            #obtener datos de imagen
            height, width, channel = image.shape
            step= channel*width
            #crear QImage para imagen
            qImg=QImage(image.data,width,height,step,QImage.Format_RGB888)
            #mostrar en el label
            self.ui.LIVE.setPixmap(QPixmap.fromImage(qImg))
        except:
            pass

    #Funciona para visualizar el stream DEPTH
    def ViewDepth(self, depth):
        try:
            image_depth = depth
            #conversion a RGB
            image2= cv2.cvtColor(image_depth, cv2.COLOR_BGR2RGB)
            #obtener datos de imagen
            height2, width2, channel2 = image2.shape
            step2= channel2*width2
            #crear QImage para imagen
            qImg2=QImage(image2.data,width2,height2,step2,QImage.Format_RGB888)
            #mostrar en el label
            self.ui.DEPTH_LIVE.setPixmap(QPixmap.fromImage(qImg2))
        except:
            pass

    #Tabla 1 muestra la clase del caving y el numero de caving de cada clase en tiempo real
    def ViewTable(self):
        global decision_dinamicos

        #Son los valores iniciales del conteo de cada tipo de caving
        Data_table = {'Angular': 0.000, 'Tabular': 0.000, 'Retrabajados': 0.00, 'Blocoso': 0.00, 'Splintered': 0.00, 'SlickenSides' : 0.00}
        Data_names = ['',' ','  ','   ','    ','     ']
        Data_values = clases_finales
        
        #Vamos a crear la grafica
        self.fig, self.axs = plt.subplots(figsize=(5, 5), sharey=True)
        self.axs.bar(Data_names, Data_values)
        self.axs.tick_params(axis='x', colors='white')
        self.axs.tick_params(axis='y', colors='white')
        self.axs.set_xticklabels(Data_names, rotation=45)
        
        #Actualizamos el valor de cada clase a su respectivo visualizador en la interfaz
        self.ui.a_n.setText(f'{str(Data_values[0])}')
        self.ui.a_n_2.setText(f'{str(Data_values[1])}')
        self.ui.a_n_3.setText(f'{str(Data_values[2])}')
        self.ui.a_n_4.setText(f'{str(Data_values[3])}')
        self.ui.a_n_5.setText(f'{str(Data_values[4])}')
        self.ui.a_n_6.setText(f'{str(Data_values[5])}')

        try:
            #Actualizamos el valor del volumen en la interfaz
            self.ui.VIEW_VOLUMEN.setText(f'{int(volumen_visor)} mm続')
        except:
            #En caso de no recibir valor de volumen por defecto es 0
             self.ui.VIEW_VOLUMEN.setText('0 mm続')
        try:
            #Teniendo el volumen y la densidad hallamos el valor de la masa de los cavings en mm cubicos
            mass_flow_value = self.density * int(volumen_visor) / 1000
        except:
            pass
        global activador_dinamico
        try:
            #Actualizamos el valor de masa en la interfaz
            self.ui.VIEW_MASS_1.setText(f'{int(mass_flow_value)} gr')
            self.guardador_masa = int(mass_flow_value)
        except:
            #En caso de no recibir valor de masa por defecto es 0 g
            self.ui.VIEW_MASS_1.setText('0 gr')

        
        try:
            #Se coloca para borrar la imagen anterior que fue mostrada
            self.borrar_img('imagen.png')
        except:
            #Se usa para la primera imagen ya que no hay imagen anterior por eliminar
            self.fig.savefig('imagen.png', transparent=True)
            #lo usamos para que no se quede sin memoria de abrir tantas imagenes el pc
            plt.close(self.fig)
        
        #Actualizamos la imagen que estamos creando en este momento y la guardamos
        self.fig.savefig('imagen.png', transparent=True)
        #Cerramos la imagen que el codigo esta usando
        plt.close(self.fig)
        
        #Creamos un retrato de la imagen para poder mostrarlo
        pixmap = QPixmap('imagen.png')
        #Actualizamos la imagen
        self.ui.TABLE.setPixmap(pixmap)     

    def ViewTable_1(self): 
        
        #Son los valores iniciales del conteo de cada tipo de caving
        Data_names = ['',' ','  ','   ','    ','     ']
        Data_values = clases_finales
        
        #Vamos a crear la grafica
        self.fig, self.axs = plt.subplots(figsize=(5, 5), sharey=True)
        self.axs.bar(Data_names, Data_values)
        self.axs.tick_params(axis='x', colors='white')
        self.axs.tick_params(axis='y', colors='white')
        self.axs.set_xticklabels(Data_names, rotation=45)
        
        #Actualizamos el valor de cada clase a su respectivo visualizador en la interfaz
        
        self.ui.a_n_3.setText(f'{str(Data_values[2])}')
        
        try:
            #Actualizamos el valor del volumen en la interfaz
            self.ui.VIEW_VOLUMEN.setText(f'{int(volumen_visor)} mm続')
        except:
            #En caso de no recibir valor de volumen por defecto es 0
             self.ui.VIEW_VOLUMEN.setText('0 mm続')
        try:
            #Teniendo el volumen y la densidad hallamos el valor de la masa de los cavings en mm cubicos
            mass_flow_value = self.density * int(volumen_visor) / 1000
        except:
            pass
        global activador_dinamico
        try:
            #Actualizamos el valor de masa en la interfaz
            self.ui.VIEW_MASS_1.setText(f'{int(mass_flow_value)} gr')
            self.guardador_masa = int(mass_flow_value)
        except:
            #En caso de no recibir valor de masa por defecto es 0 g
            self.ui.VIEW_MASS_1.setText('0 gr')

        
        try:
            #Se coloca para borrar la imagen anterior que fue mostrada
            self.borrar_img('imagen.png')
        except:
            #Se usa para la primera imagen ya que no hay imagen anterior por eliminar
            self.fig.savefig('imagen.png', transparent=True)
            #lo usamos para que no se quede sin memoria de abrir tantas imagenes el pc
            plt.close(self.fig)
        
        #Actualizamos la imagen que estamos creando en este momento y la guardamos
        self.fig.savefig('imagen.png', transparent=True)
        #Cerramos la imagen que el codigo esta usando
        plt.close(self.fig)
        
        #Creamos un retrato de la imagen para poder mostrarlo
        pixmap = QPixmap('imagen.png')
        #Actualizamos la imagen
        self.ui.TABLE.setPixmap(pixmap)       

    def ViewTable2(self):
        global conteo_dinamico
        global mode_clasificacion
        #contador para guardar cada 30 registros una foto 
        self.registro_cavings_min = self.registro_cavings_min+1 
        #Actualiza las fechas para visualizar los 30 ultimos

        for j in range(29):
            self.index_date[29-j] =  self.index_date[28-j]  

            #Actualiza los datos para visualizar los 30 ultimos
            self.data_cavings['Angular'][29-j] = self.data_cavings['Angular'][28-j] 
            self.data_cavings['Tabular'][29-j] = self.data_cavings['Tabular'][28-j]
            self.data_cavings['Retrabajados'][29-j] = self.data_cavings['Retrabajados'][28-j] 
            self.data_cavings['Blocoso'][29-j] = self.data_cavings['Blocoso'][28-j]  
            self.data_cavings['Splintered'][29-j] = self.data_cavings['Splintered'][28-j]  
            self.data_cavings['SlickenSides'][29-j] =  self.data_cavings['SlickenSides'][28-j]
            self.data_cavings['cavings'][29-j] =  self.data_cavings['cavings'][28-j]

        #Tabla 2
        self.index_date[0] = f'{time.strftime("%H:%M")}'

        self.data_cavings['Angular'][0] = conteo_dinamico[0]
        self.data_cavings['Tabular'][0] = conteo_dinamico[1]
        if mode_clasificacion==True:
            self.data_cavings['Splintered'][0] = conteo_dinamico[2] 
            self.data_cavings['cavings'][0] = 0
        else:
            self.data_cavings['Splintered'][0] = 0
            self.data_cavings['cavings'][0] = conteo_dinamico[2] 
        self.data_cavings['Retrabajados'][0] = conteo_dinamico[3] 
        self.data_cavings['SlickenSides'][0] = conteo_dinamico[4]
        self.data_cavings['Blocoso'][0] = conteo_dinamico[5]

        #Para las horas
        self.data_cavings2['Angular'][0] = self.data_cavings2['Angular'][0] + conteo_dinamico[0]
        self.data_cavings2['Tabular'][0] = self.data_cavings2['Tabular'][0]+ conteo_dinamico[1]
        if mode_clasificacion==True:
            self.data_cavings2['Splintered'][0] = self.data_cavings2['Splintered'][0]+  conteo_dinamico[2] 
            self.data_cavings2['cavings'][0] = 0
        else:
            self.data_cavings2['Splintered'][0] = 0
            self.data_cavings2['cavings'][0] = self.data_cavings2['cavings'][0]+conteo_dinamico[2] 
        self.data_cavings2['Retrabajados'][0] = self.data_cavings2['Retrabajados'][0]+conteo_dinamico[3] 
        self.data_cavings2['SlickenSides'][0] = self.data_cavings2['SlickenSides'][0] + conteo_dinamico[4]
        self.data_cavings2['Blocoso'][0] = self.data_cavings2['Blocoso'][0]+conteo_dinamico[5]
        

        conteo_dinamico = ([0,0,0,0,0,0])

        df=pd.DataFrame(self.data_cavings,index = self.index_date) 
        df2 =pd.DataFrame(self.data_cavings,index = self.index_date) 

        ax = df.plot(kind="barh",stacked=True,figsize=(9,9))
        ax2 = df2.plot(kind="barh",stacked=True,figsize=(9,9))

        fig_2 = ax2.get_figure()

        plt.title(f'Cavings/min \n {time.strftime("%d %B, %Y")}', color = 'white')
        plt.legend(loc="lower left",bbox_to_anchor=(0.74,0.75))

        # set various colors
        ax.spines['bottom'].set_color('white')
        ax.spines['top'].set_color('white') 
        ax.spines['right'].set_color('white')
        ax.spines['left'].set_color('white')
        ax.xaxis.label.set_color('white')
        ax.yaxis.label.set_color('white')
        ax.tick_params(colors='white', which='both')  # 'both' refers to minor and major axes

        fig = ax.get_figure()

        if self.registro_cavings_min==30:
            try:
                os.mkdir(f'registros/{time.strftime("%d %B, %Y")}')
            except:
                print("Directorio ya creado")
            fig_2.savefig(f'registros/{time.strftime("%d %B, %Y")}/{self.index_date[29][0:2]}_{self.index_date[29][3:5]}.jpg')
            plt.close(fig_2)
            #hacer carpeta para agrupar por dia
            self.registro_cavings_min = 0
            self.registro_ciclos = self.registro_ciclos+1

        if self.registro_ciclos == 2:
            self.ViewTable4()
            self.registro_ciclos = 0
            
        fig.savefig('imagen2.png',transparent=True)
        plt.close(fig)
        plt.close(fig_2)
        
        pixmap = QPixmap('imagen2.png')
        self.ui.TABLE2.setPixmap(pixmap)

    def ViewTable3(self):
        self.registro_cavings_min2 = self.registro_cavings_min2+1 
        global activador_dinamico
        guardador_masa_1 = 0

        for j in range(29):
            #Actualiza los datos para visualizar los 30 ultimos
            self.data_mass['gr/min'][29-j] = self.data_mass['gr/min'][28-j] 

        if decision_dinamicos==True:
            if activador_dinamico==True:
                guardador_masa_1 = self.guardador_masa
                self.data_mass['gr/min'][0] = guardador_masa_1
                activador_dinamico = False
            else:
                self.data_mass['gr/min'][0] = 0
        else:
            self.data_mass['gr/min'][0] = self.guardador_masa

        if decision_dinamicos==True:
            if activador_dinamico==True:
                guardador_masa_1 = self.guardador_masa
                self.data_mass2['gr/hora'][0] = self.data_mass2['gr/hora'][0] + guardador_masa_1
                activador_dinamico = False
            else:
                self.data_mass2['gr/hora'][0] = 0
        else:
            self.data_mass2['gr/hora'][0] = self.data_mass2['gr/hora'][0] + self.guardador_masa
            
        guardador_masa_1 = 0
        self.guardador_masa = 0

        df=pd.DataFrame(self.data_mass,index = self.index_date) 

        ax = df.plot(kind="barh",stacked=True,figsize=(9,9))
        ax2 = df.plot(kind="barh",stacked=True,figsize=(9,9))
        fig2 = ax2.get_figure()

        plt.title(f'Flujo m叩sico/min \n {time.strftime("%d %B, %Y")}', color = 'white')
        plt.legend(loc="lower left",bbox_to_anchor=(0.83,0.94))

        # set various colors
        ax.spines['bottom'].set_color('white')
        ax.spines['top'].set_color('white') 
        ax.spines['right'].set_color('white')
        ax.spines['left'].set_color('white')
        ax.xaxis.label.set_color('white')
        ax.yaxis.label.set_color('white')
        ax.tick_params(colors='white', which='both')  # 'both' refers to minor and major axes

        fig = ax.get_figure()

        if self.registro_cavings_min2==30:
            try:
                os.mkdir(f'registros/{time.strftime("%d %B, %Y")}')
            except:
                print("Directorio ya creado")
            fig2.savefig(f'registros/{time.strftime("%d %B, %Y")}/{self.index_date[29][0:2]}_{self.index_date[29][3:5]}_Flujo_masico.jpg')
            plt.close(fig2)
            #hacer carpeta para agrupar por dia
            self.registro_cavings_min2 = 0
            self.registro_ciclos2 = self.registro_ciclos2+1
        
        if self.registro_ciclos2 == 2:
            self.ViewTable5()
            self.registro_ciclos2 = 0
            
        fig.savefig('imagen3.png',transparent=True)
        plt.close(fig)
        plt.close(fig2)
        
        pixmap = QPixmap('imagen3.png')
        self.ui.TABLE3.setPixmap(pixmap)

    def ViewTable4(self):
        for j in range(29):
            self.index_date2[29-j] =  self.index_date2[28-j]  

            #Actualiza los datos para visualizar los 30 ultimos
            self.data_cavings2['Angular'][29-j] = self.data_cavings2['Angular'][28-j] 
            self.data_cavings2['Tabular'][29-j] = self.data_cavings2['Tabular'][28-j]
            self.data_cavings2['Retrabajados'][29-j] = self.data_cavings2['Retrabajados'][28-j] 
            self.data_cavings2['Blocoso'][29-j] = self.data_cavings2['Blocoso'][28-j]  
            self.data_cavings2['Splintered'][29-j] = self.data_cavings2['Splintered'][28-j]  
            self.data_cavings2['SlickenSides'][29-j] =  self.data_cavings2['SlickenSides'][28-j]
            self.data_cavings2['cavings'][29-j] =  self.data_cavings2['cavings'][28-j]
        
        self.index_date2[0] = f'{time.strftime("%H:%M")}'

        df=pd.DataFrame(self.data_cavings2,index = self.index_date2) 

        ax = df.plot(kind="barh",stacked=True,figsize=(9,9))
        ax2 = df.plot(kind="barh",stacked=True,figsize=(9,9))
        fig2 = ax2.get_figure()
        
        plt.title(f'Cavings/hora \n {time.strftime("%d %B, %Y")}', color = 'white')
        plt.legend(loc="lower left",bbox_to_anchor=(0.74,0.75))

        # set various colors
        ax.spines['bottom'].set_color('white')
        ax.spines['top'].set_color('white') 
        ax.spines['right'].set_color('white')
        ax.spines['left'].set_color('white')
        ax.xaxis.label.set_color('white')
        ax.yaxis.label.set_color('white')
        ax.tick_params(colors='white', which='both')  # 'both' refers to minor and major axes

        fig = ax.get_figure()

        if self.registro_cavings_hour==24:
            try:
                os.mkdir(f'registros/{time.strftime("%d %B, %Y")}')
            except:
                print("Directorio ya creado")
            fig2.savefig(f'registros/HORA_{time.strftime("%d %B, %Y")}/Hour{self.index_date2[29][0:2]}_{self.index_date2[29][3:5]}.jpg')
            plt.close(fig2)
            #hacer carpeta para agrupar por dia
            self.registro_cavings_hour = 0
            
        fig.savefig('imagen4.png',transparent=True)
        plt.close(fig)
        plt.close(fig2)
        
        pixmap = QPixmap('imagen4.png')
        self.ui.TABLE2_3.setPixmap(pixmap)

        self.data_cavings2['Angular'][0] = 0
        self.data_cavings2['Tabular'][0] = 0
        if mode_clasificacion==True:
            self.data_cavings2['Splintered'][0] = 0
            self.data_cavings2['cavings'][0] = 0
        else:
            self.data_cavings2['Splintered'][0] = 0
            self.data_cavings2['cavings'][0] = 0
        self.data_cavings2['Retrabajados'][0] = 0
        self.data_cavings2['SlickenSides'][0] = 0
        self.data_cavings2['Blocoso'][0] = 0

    def ViewTable5(self):
        global activador_dinamico
        for j in range(29):
            #Actualiza los datos para visualizar los 30 ultimos
            self.data_mass2['gr/hora'][29-j] = self.data_mass2['gr/hora'][28-j] 
        
        df=pd.DataFrame(self.data_mass2,index = self.index_date2) 

        ax = df.plot(kind="barh",stacked=True,figsize=(9,9))
        ax2 = df.plot(kind="barh",stacked=True,figsize=(9,9))
        fig2 = ax2.get_figure()
        
        plt.title(f'Flujo m叩sico/hora \n {time.strftime("%d %B, %Y")}', color = 'white')
        plt.legend(loc="lower left",bbox_to_anchor=(0.82,0.94))

        # set various colors
        ax.spines['bottom'].set_color('white')
        ax.spines['top'].set_color('white') 
        ax.spines['right'].set_color('white')
        ax.spines['left'].set_color('white')
        ax.xaxis.label.set_color('white')
        ax.yaxis.label.set_color('white')
        ax.tick_params(colors='white', which='both')  # 'both' refers to minor and major axes

        fig = ax.get_figure()

        if self.registro_cavings_hour2==24:
            try:
                os.mkdir(f'registros/{time.strftime("%d %B, %Y")}')
            except:
                print("Directorio ya creado")
            fig2.savefig(f'registros/HORA_{time.strftime("%d %B, %Y")}/{self.index_date2[29][0:2]}_{self.index_date2[29][3:5]}_Flujo_masico.jpg')
            plt.close(fig2)
            #hacer carpeta para agrupar por dia
            self.registro_cavings_hour2 = 0
            
        fig.savefig('imagen5.png',transparent=True)
        plt.close(fig)
        plt.close(fig2)
        
        pixmap = QPixmap('imagen5.png')
        self.ui.TABLE3_3.setPixmap(pixmap)

        if decision_dinamicos==True:
            if activador_dinamico==True:
                self.data_mass2['gr/hora'][0] = 0
                activador_dinamico = False
            else:
                self.data_mass2['gr/hora'][0] = 0
        else:
            self.data_mass2['gr/hora'][0] = 0

    def QuitAll(self):
        self.close()
        sys.exit() 

if __name__ == "__main__":
    app = QtWidgets.QApplication(sys.argv)
    os.system ("cls") 
    w = MainWindow()
    w.show()
    sys.exit(app.exec_())

'--------------------------'
'----DESARROLLADO POR:-----'
'--------TRILOBYTE---------'
'------Oscar-Olejua--------'
'------Cesar-Herrera-------'
'------Carlos-Lopez--------'
'--------------------------'